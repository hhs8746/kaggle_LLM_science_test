{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Preprocessing the dataset","metadata":{}},{"cell_type":"code","source":"#https://www.kaggle.com/code/radek1/new-dataset-deberta-v3-large-training을 보고 작성했습니다.","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from typing import Optional, Union\nimport pandas as pd\nimport numpy as np\nimport torch\nfrom datasets import Dataset\nfrom dataclasses import dataclass\nfrom transformers import AutoTokenizer\nfrom transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\nfrom transformers import AutoModelForMultipleChoice, TrainingArguments, Trainer, AutoModel\n\ndeberta_v3_large = '/kaggle/input/deberta-v3-large-hf-weights'","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-07-27T09:52:57.221272Z","iopub.execute_input":"2023-07-27T09:52:57.221646Z","iopub.status.idle":"2023-07-27T09:53:11.797649Z","shell.execute_reply.started":"2023-07-27T09:52:57.221611Z","shell.execute_reply":"2023-07-27T09:53:11.796636Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"markdown","source":"We begin by loading and processing the train data.","metadata":{}},{"cell_type":"code","source":"df_train = pd.read_csv('/kaggle/input/kaggle-llm-science-exam/train.csv')\ndf_train = df_train.drop(columns=\"id\")\ndf_train.shape","metadata":{"execution":{"iopub.status.busy":"2023-07-27T09:53:47.801661Z","iopub.execute_input":"2023-07-27T09:53:47.802025Z","iopub.status.idle":"2023-07-27T09:53:47.829046Z","shell.execute_reply.started":"2023-07-27T09:53:47.801995Z","shell.execute_reply":"2023-07-27T09:53:47.828003Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"(200, 7)"},"metadata":{}}]},{"cell_type":"markdown","source":"Let's add another 500 examples to the train set!","metadata":{}},{"cell_type":"code","source":"df_train = pd.concat([\n    df_train,\n    pd.read_csv('/kaggle/input/additional-train-data-for-llm-science-exam/extra_train_set.csv'),\n])\ndf_train.reset_index(inplace=True, drop=True)\ndf_train.shape","metadata":{"execution":{"iopub.status.busy":"2023-07-27T09:53:49.796459Z","iopub.execute_input":"2023-07-27T09:53:49.797142Z","iopub.status.idle":"2023-07-27T09:53:49.820042Z","shell.execute_reply.started":"2023-07-27T09:53:49.797106Z","shell.execute_reply":"2023-07-27T09:53:49.818657Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"(700, 7)"},"metadata":{}}]},{"cell_type":"markdown","source":"Now that we have gone from 200 -> 700 train examples, let us preprocess the data and begin training.","metadata":{}},{"cell_type":"code","source":"option_to_index = {option: idx for idx, option in enumerate('ABCDE')}\nindex_to_option = {v: k for k,v in option_to_index.items()}\n\ndef preprocess(example):\n    first_sentence = [example['prompt']] * 5\n    second_sentences = [example[option] for option in 'ABCDE']\n    tokenized_example = tokenizer(first_sentence, second_sentences, truncation=True)\n    tokenized_example['label'] = option_to_index[example['answer']]\n    \n    return tokenized_example\n\n@dataclass\nclass DataCollatorForMultipleChoice:\n    tokenizer: PreTrainedTokenizerBase\n    padding: Union[bool, str, PaddingStrategy] = True\n    max_length: Optional[int] = None\n    pad_to_multiple_of: Optional[int] = None\n    \n    def __call__(self, features):\n        label_name = 'label' if 'label' in features[0].keys() else 'labels'\n        labels = [feature.pop(label_name) for feature in features]\n        batch_size = len(features)\n        num_choices = len(features[0]['input_ids'])\n        flattened_features = [\n            [{k: v[i] for k, v in feature.items()} for i in range(num_choices)] for feature in features\n        ]\n        flattened_features = sum(flattened_features, [])\n        \n        batch = self.tokenizer.pad(\n            flattened_features,\n            padding=self.padding,\n            max_length=self.max_length,\n            pad_to_multiple_of=self.pad_to_multiple_of,\n            return_tensors='pt',\n        )\n        batch = {k: v.view(batch_size, num_choices, -1) for k, v in batch.items()}\n        batch['labels'] = torch.tensor(labels, dtype=torch.int64)\n        return batch","metadata":{"execution":{"iopub.status.busy":"2023-07-27T09:53:51.668379Z","iopub.execute_input":"2023-07-27T09:53:51.669073Z","iopub.status.idle":"2023-07-27T09:53:51.683243Z","shell.execute_reply.started":"2023-07-27T09:53:51.669039Z","shell.execute_reply":"2023-07-27T09:53:51.682259Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"We first create a HuggingFace `Dataset`.","metadata":{"execution":{"iopub.status.busy":"2023-07-21T03:38:13.804849Z","iopub.execute_input":"2023-07-21T03:38:13.805215Z","iopub.status.idle":"2023-07-21T03:38:13.814629Z","shell.execute_reply.started":"2023-07-21T03:38:13.805184Z","shell.execute_reply":"2023-07-21T03:38:13.813302Z"}}},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(deberta_v3_large)\n\ndataset = Dataset.from_pandas(df_train)\ndataset","metadata":{"execution":{"iopub.status.busy":"2023-07-27T09:53:55.356260Z","iopub.execute_input":"2023-07-27T09:53:55.356647Z","iopub.status.idle":"2023-07-27T09:53:56.486944Z","shell.execute_reply.started":"2023-07-27T09:53:55.356612Z","shell.execute_reply":"2023-07-27T09:53:56.485859Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n/opt/conda/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:454: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n  warnings.warn(\nSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['prompt', 'A', 'B', 'C', 'D', 'E', 'answer'],\n    num_rows: 700\n})"},"metadata":{}}]},{"cell_type":"markdown","source":"And let us now preprocess the examples for training.","metadata":{}},{"cell_type":"code","source":"tokenized_dataset = dataset.map(preprocess, remove_columns=['prompt', 'A', 'B', 'C', 'D', 'E', 'answer'])\ntokenized_dataset","metadata":{"execution":{"iopub.status.busy":"2023-07-27T09:53:58.758863Z","iopub.execute_input":"2023-07-27T09:53:58.760890Z","iopub.status.idle":"2023-07-27T09:53:59.629864Z","shell.execute_reply.started":"2023-07-27T09:53:58.760846Z","shell.execute_reply":"2023-07-27T09:53:59.628806Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/700 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eb8627f2f5a1413da5cdab6c6950232e"}},"metadata":{}},{"name":"stderr","text":"Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n","output_type":"stream"},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['input_ids', 'token_type_ids', 'attention_mask', 'label'],\n    num_rows: 700\n})"},"metadata":{}}]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"training_args = TrainingArguments(\n    warmup_ratio=0.8,\n    learning_rate=5e-6,\n    per_device_train_batch_size=1,\n    per_device_eval_batch_size=2,\n    num_train_epochs=6,\n    report_to='none',\n    output_dir='.',\n\n)\n\nmodel = AutoModelForMultipleChoice.from_pretrained(deberta_v3_large)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    tokenizer=tokenizer,\n    data_collator=DataCollatorForMultipleChoice(tokenizer=tokenizer),\n    train_dataset=tokenized_dataset,\n)\n\ntrainer.train()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predicting on the test set","metadata":{}},{"cell_type":"markdown","source":"Now that we have trained our model, let us predict on the test set.","metadata":{}},{"cell_type":"code","source":"test_df = pd.read_csv('/kaggle/input/kaggle-llm-science-exam/test.csv')\ntest_df['answer'] = 'A' # dummy answer that allows us to preprocess the test dataset just like we preprocessed the train dataset\n\ntokenized_test_dataset = Dataset.from_pandas(test_df.drop(columns=['id'])).map(preprocess, remove_columns=['prompt', 'A', 'B', 'C', 'D', 'E'])","metadata":{"execution":{"iopub.status.busy":"2023-07-21T03:51:44.400043Z","iopub.execute_input":"2023-07-21T03:51:44.400445Z","iopub.status.idle":"2023-07-21T03:51:44.681849Z","shell.execute_reply.started":"2023-07-21T03:51:44.400416Z","shell.execute_reply":"2023-07-21T03:51:44.680916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_predictions = trainer.predict(tokenized_test_dataset).predictions\ntest_predictions[:4]","metadata":{"execution":{"iopub.status.busy":"2023-07-21T03:51:48.050713Z","iopub.execute_input":"2023-07-21T03:51:48.051096Z","iopub.status.idle":"2023-07-21T03:51:58.358622Z","shell.execute_reply.started":"2023-07-21T03:51:48.051066Z","shell.execute_reply":"2023-07-21T03:51:58.35729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The predictions are values output from the last layer of our neural network.\n\nLet's obtain the predicted answer ids by sorting them from largest to the smallest.","metadata":{}},{"cell_type":"code","source":"predictions_as_ids = np.argsort(-test_predictions, 1)\npredictions_as_ids[:3]","metadata":{"execution":{"iopub.status.busy":"2023-07-21T03:58:13.726252Z","iopub.execute_input":"2023-07-21T03:58:13.726619Z","iopub.status.idle":"2023-07-21T03:58:13.734293Z","shell.execute_reply.started":"2023-07-21T03:58:13.726591Z","shell.execute_reply":"2023-07-21T03:58:13.733158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let us now assign a letter corresponding to each predicted id (0 -> 'A', 1 -> 'B', etc). ","metadata":{}},{"cell_type":"code","source":"predictions_as_answer_letters = np.array(list('ABCDE'))[predictions_as_ids]\npredictions_as_answer_letters[:3]","metadata":{"execution":{"iopub.status.busy":"2023-07-21T03:59:29.450138Z","iopub.execute_input":"2023-07-21T03:59:29.450514Z","iopub.status.idle":"2023-07-21T03:59:29.457655Z","shell.execute_reply.started":"2023-07-21T03:59:29.450482Z","shell.execute_reply":"2023-07-21T03:59:29.456704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions_as_string = test_df['prediction'] = [\n    ' '.join(row) for row in predictions_as_answer_letters[:, :3]\n]\npredictions_as_string[:3]","metadata":{"execution":{"iopub.status.busy":"2023-07-21T04:00:38.222246Z","iopub.execute_input":"2023-07-21T04:00:38.222623Z","iopub.status.idle":"2023-07-21T04:00:38.230438Z","shell.execute_reply.started":"2023-07-21T04:00:38.222595Z","shell.execute_reply":"2023-07-21T04:00:38.229338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = test_df[['id', 'prediction']]\nsubmission.to_csv('submission.csv', index=False)\n\npd.read_csv('submission.csv').head()","metadata":{"execution":{"iopub.status.busy":"2023-07-21T04:01:22.999308Z","iopub.execute_input":"2023-07-21T04:01:22.999674Z","iopub.status.idle":"2023-07-21T04:01:23.015664Z","shell.execute_reply.started":"2023-07-21T04:01:22.999644Z","shell.execute_reply":"2023-07-21T04:01:23.014601Z"},"trusted":true},"execution_count":null,"outputs":[]}]}