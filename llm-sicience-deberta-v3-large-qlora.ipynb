{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Preprocessing the dataset","metadata":{}},{"cell_type":"code","source":"#https://www.kaggle.com/code/radek1/new-dataset-deberta-v3-large-training을 보고 작성했습니다.","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -q -U bitsandbytes\n!pip install -q -U git+https://github.com/huggingface/transformers.git\n!pip install -q -U git+https://github.com/huggingface/peft.git\n!pip install -q -U git+https://github.com/huggingface/accelerate.git","metadata":{"execution":{"iopub.status.busy":"2023-07-31T06:07:50.419408Z","iopub.execute_input":"2023-07-31T06:07:50.420251Z","iopub.status.idle":"2023-07-31T06:09:52.119475Z","shell.execute_reply.started":"2023-07-31T06:07:50.420216Z","shell.execute_reply":"2023-07-31T06:09:52.118139Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!pip install bitsandbytes","metadata":{"execution":{"iopub.status.busy":"2023-07-31T06:09:52.122020Z","iopub.execute_input":"2023-07-31T06:09:52.123178Z","iopub.status.idle":"2023-07-31T06:10:04.539640Z","shell.execute_reply.started":"2023-07-31T06:09:52.123137Z","shell.execute_reply":"2023-07-31T06:10:04.538402Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: bitsandbytes in /opt/conda/lib/python3.10/site-packages (0.41.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"from typing import Optional, Union\nimport pandas as pd\nimport numpy as np\nimport torch\nfrom datasets import Dataset\nfrom dataclasses import dataclass\nfrom transformers import AutoTokenizer\nfrom transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\nfrom transformers import AutoModelForMultipleChoice, TrainingArguments, Trainer, AutoModel\n\ndeberta_v3_large = '/kaggle/input/deberta-v3-large-hf-weights'","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-07-31T06:10:04.542603Z","iopub.execute_input":"2023-07-31T06:10:04.543553Z","iopub.status.idle":"2023-07-31T06:10:18.173352Z","shell.execute_reply.started":"2023-07-31T06:10:04.543516Z","shell.execute_reply":"2023-07-31T06:10:18.172404Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"markdown","source":"We begin by loading and processing the train data.","metadata":{}},{"cell_type":"code","source":"df_train = pd.read_csv('/kaggle/input/llm-science-dataset/Combined Dataset.csv')\ndf_train = df_train.drop(columns=\"id\")\ndf_train.shape","metadata":{"execution":{"iopub.status.busy":"2023-07-31T06:10:18.175990Z","iopub.execute_input":"2023-07-31T06:10:18.176430Z","iopub.status.idle":"2023-07-31T06:10:18.377508Z","shell.execute_reply.started":"2023-07-31T06:10:18.176395Z","shell.execute_reply":"2023-07-31T06:10:18.376541Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"(11963, 7)"},"metadata":{}}]},{"cell_type":"markdown","source":"Let's add another 500 examples to the train set!","metadata":{}},{"cell_type":"code","source":"# df_train = pd.concat([\n#     df_train,\n#     pd.read_csv('/kaggle/input/additional-train-data-for-llm-science-exam/extra_train_set.csv'),\n# ])\n# df_train.reset_index(inplace=True, drop=True)\n# df_train.shape","metadata":{"execution":{"iopub.status.busy":"2023-07-31T06:10:18.378980Z","iopub.execute_input":"2023-07-31T06:10:18.379872Z","iopub.status.idle":"2023-07-31T06:10:18.384758Z","shell.execute_reply.started":"2023-07-31T06:10:18.379834Z","shell.execute_reply":"2023-07-31T06:10:18.383591Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"df_train","metadata":{"execution":{"iopub.status.busy":"2023-07-31T06:10:18.386248Z","iopub.execute_input":"2023-07-31T06:10:18.387324Z","iopub.status.idle":"2023-07-31T06:10:18.414687Z","shell.execute_reply.started":"2023-07-31T06:10:18.387257Z","shell.execute_reply":"2023-07-31T06:10:18.413672Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                                                  prompt  \\\n0      Which of the following statements accurately d...   \n1      Which of the following is an accurate definiti...   \n2      Which of the following statements accurately d...   \n3      What is the significance of regularization in ...   \n4      Which of the following statements accurately d...   \n...                                                  ...   \n11958  Are most developing-country farmers engaged in...   \n11959  Which of the following statements about protei...   \n11960  Which of the following is closest to the amoun...   \n11961  From the list of oral microorganisms, which is...   \n11962  Which statement about the oral phase of digest...   \n\n                                                       A  \\\n0      MOND is a theory that reduces the observed mis...   \n1      Dynamic scaling refers to the evolution of sel...   \n2      The triskeles symbol was reconstructed as a fe...   \n3      Regularizing the mass-energy of an electron wi...   \n4      The angular spacing of features in the diffrac...   \n...                                                  ...   \n11958                Almost all are subsistence farmers.   \n11959      All the information in DNA codes for proteins   \n11960                      2 mol retinol /mol ß-carotene   \n11961                                Mutans streptococci   \n11962  About 2% of the energy content of food is expe...   \n\n                                                       B  \\\n0      MOND is a theory that increases the discrepanc...   \n1      Dynamic scaling refers to the non-evolution of...   \n2      The triskeles symbol is a representation of th...   \n3      Regularizing the mass-energy of an electron wi...   \n4      The angular spacing of features in the diffrac...   \n...                                                  ...   \n11958  Very few engage in subsistence production, ins...   \n11959  The mRNA formed by transcription of a region o...   \n11960                      1 mol retinol /mol ß-carotene   \n11961                                     bifidobacteria   \n11962  Swallowing involves contraction and relaxation...   \n\n                                                       C  \\\n0      MOND is a theory that explains the missing bar...   \n1      Dynamic scaling refers to the evolution of sel...   \n2      The triskeles symbol is a representation of a ...   \n3      Regularizing the mass-energy of an electron wi...   \n4      The angular spacing of features in the diffrac...   \n...                                                  ...   \n11958  Virtually all small-scale producers are engage...   \n11959  Both strands of DNA are transcribed to form mRNA.   \n11960                   0.15 mol retinol /mol ß-carotene   \n11961                                       Lactobacilli   \n11962  The biofilm covering tooth enamel contains sev...   \n\n                                                       D  \\\n0      MOND is a theory that reduces the discrepancy ...   \n1      Dynamic scaling refers to the non-evolution of...   \n2      The triskeles symbol represents three interloc...   \n3      Regularizing the mass-energy of an electron wi...   \n4      The angular spacing of features in the diffrac...   \n...                                                  ...   \n11958         37% engage in pure subsistence production.   \n11959  The RNA formed by transcription of DNA undergo...   \n11960                    0.1 mol retinol /mol ß-carotene   \n11961                                      P. gingivalis   \n11962  Salivary amylase digests the dextran film on t...   \n\n                                                       E answer  \n0      MOND is a theory that eliminates the observed ...      D  \n1      Dynamic scaling refers to the evolution of sel...      A  \n2      The triskeles symbol is a representation of th...      A  \n3      Regularizing the mass-energy of an electron wi...      C  \n4      The angular spacing of features in the diffrac...      D  \n...                                                  ...    ...  \n11958         37% engage in pure subsistence production.      C  \n11959      All the information in DNA codes for proteins      D  \n11960                      1 mol retinol /mol ß-carotene      C  \n11961                                       Lactobacilli      A  \n11962  The biofilm covering tooth enamel contains sev...      D  \n\n[11963 rows x 7 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prompt</th>\n      <th>A</th>\n      <th>B</th>\n      <th>C</th>\n      <th>D</th>\n      <th>E</th>\n      <th>answer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Which of the following statements accurately d...</td>\n      <td>MOND is a theory that reduces the observed mis...</td>\n      <td>MOND is a theory that increases the discrepanc...</td>\n      <td>MOND is a theory that explains the missing bar...</td>\n      <td>MOND is a theory that reduces the discrepancy ...</td>\n      <td>MOND is a theory that eliminates the observed ...</td>\n      <td>D</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Which of the following is an accurate definiti...</td>\n      <td>Dynamic scaling refers to the evolution of sel...</td>\n      <td>Dynamic scaling refers to the non-evolution of...</td>\n      <td>Dynamic scaling refers to the evolution of sel...</td>\n      <td>Dynamic scaling refers to the non-evolution of...</td>\n      <td>Dynamic scaling refers to the evolution of sel...</td>\n      <td>A</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Which of the following statements accurately d...</td>\n      <td>The triskeles symbol was reconstructed as a fe...</td>\n      <td>The triskeles symbol is a representation of th...</td>\n      <td>The triskeles symbol is a representation of a ...</td>\n      <td>The triskeles symbol represents three interloc...</td>\n      <td>The triskeles symbol is a representation of th...</td>\n      <td>A</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>What is the significance of regularization in ...</td>\n      <td>Regularizing the mass-energy of an electron wi...</td>\n      <td>Regularizing the mass-energy of an electron wi...</td>\n      <td>Regularizing the mass-energy of an electron wi...</td>\n      <td>Regularizing the mass-energy of an electron wi...</td>\n      <td>Regularizing the mass-energy of an electron wi...</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Which of the following statements accurately d...</td>\n      <td>The angular spacing of features in the diffrac...</td>\n      <td>The angular spacing of features in the diffrac...</td>\n      <td>The angular spacing of features in the diffrac...</td>\n      <td>The angular spacing of features in the diffrac...</td>\n      <td>The angular spacing of features in the diffrac...</td>\n      <td>D</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>11958</th>\n      <td>Are most developing-country farmers engaged in...</td>\n      <td>Almost all are subsistence farmers.</td>\n      <td>Very few engage in subsistence production, ins...</td>\n      <td>Virtually all small-scale producers are engage...</td>\n      <td>37% engage in pure subsistence production.</td>\n      <td>37% engage in pure subsistence production.</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>11959</th>\n      <td>Which of the following statements about protei...</td>\n      <td>All the information in DNA codes for proteins</td>\n      <td>The mRNA formed by transcription of a region o...</td>\n      <td>Both strands of DNA are transcribed to form mRNA.</td>\n      <td>The RNA formed by transcription of DNA undergo...</td>\n      <td>All the information in DNA codes for proteins</td>\n      <td>D</td>\n    </tr>\n    <tr>\n      <th>11960</th>\n      <td>Which of the following is closest to the amoun...</td>\n      <td>2 mol retinol /mol ß-carotene</td>\n      <td>1 mol retinol /mol ß-carotene</td>\n      <td>0.15 mol retinol /mol ß-carotene</td>\n      <td>0.1 mol retinol /mol ß-carotene</td>\n      <td>1 mol retinol /mol ß-carotene</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>11961</th>\n      <td>From the list of oral microorganisms, which is...</td>\n      <td>Mutans streptococci</td>\n      <td>bifidobacteria</td>\n      <td>Lactobacilli</td>\n      <td>P. gingivalis</td>\n      <td>Lactobacilli</td>\n      <td>A</td>\n    </tr>\n    <tr>\n      <th>11962</th>\n      <td>Which statement about the oral phase of digest...</td>\n      <td>About 2% of the energy content of food is expe...</td>\n      <td>Swallowing involves contraction and relaxation...</td>\n      <td>The biofilm covering tooth enamel contains sev...</td>\n      <td>Salivary amylase digests the dextran film on t...</td>\n      <td>The biofilm covering tooth enamel contains sev...</td>\n      <td>D</td>\n    </tr>\n  </tbody>\n</table>\n<p>11963 rows × 7 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"Now that we have gone from 200 -> 700 train examples, let us preprocess the data and begin training.","metadata":{}},{"cell_type":"code","source":"option_to_index = {option: idx for idx, option in enumerate('ABCDE')}\nindex_to_option = {v: k for k,v in option_to_index.items()}\n\ndef preprocess(example):\n    first_sentence = [example['prompt']] * 5\n    second_sentences = [example[option] for option in 'ABCDE']\n    tokenized_example = tokenizer(first_sentence, second_sentences, truncation=True)\n    tokenized_example['label'] = option_to_index[example['answer']]\n    \n    return tokenized_example\n\n@dataclass\nclass DataCollatorForMultipleChoice:\n    tokenizer: PreTrainedTokenizerBase\n    padding: Union[bool, str, PaddingStrategy] = True\n    max_length: Optional[int] = None\n    pad_to_multiple_of: Optional[int] = None\n    \n    def __call__(self, features):\n        label_name = 'label' if 'label' in features[0].keys() else 'labels'\n        labels = [feature.pop(label_name) for feature in features]\n        batch_size = len(features)\n        num_choices = len(features[0]['input_ids'])\n        flattened_features = [\n            [{k: v[i] for k, v in feature.items()} for i in range(num_choices)] for feature in features\n        ]\n        flattened_features = sum(flattened_features, [])\n        \n        batch = self.tokenizer.pad(\n            flattened_features,\n            padding=self.padding,\n            max_length=self.max_length,\n            pad_to_multiple_of=self.pad_to_multiple_of,\n            return_tensors='pt',\n        )\n        batch = {k: v.view(batch_size, num_choices, -1) for k, v in batch.items()}\n        batch['labels'] = torch.tensor(labels, dtype=torch.int64)\n        return batch","metadata":{"execution":{"iopub.status.busy":"2023-07-31T06:10:18.416480Z","iopub.execute_input":"2023-07-31T06:10:18.417337Z","iopub.status.idle":"2023-07-31T06:10:18.431224Z","shell.execute_reply.started":"2023-07-31T06:10:18.417298Z","shell.execute_reply":"2023-07-31T06:10:18.430020Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"We first create a HuggingFace `Dataset`.","metadata":{"execution":{"iopub.status.busy":"2023-07-21T03:38:13.804849Z","iopub.execute_input":"2023-07-21T03:38:13.805215Z","iopub.status.idle":"2023-07-21T03:38:13.814629Z","shell.execute_reply.started":"2023-07-21T03:38:13.805184Z","shell.execute_reply":"2023-07-21T03:38:13.813302Z"}}},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(deberta_v3_large)\n\ndataset = Dataset.from_pandas(df_train)\ndataset","metadata":{"execution":{"iopub.status.busy":"2023-07-31T06:10:18.432726Z","iopub.execute_input":"2023-07-31T06:10:18.433356Z","iopub.status.idle":"2023-07-31T06:10:19.698635Z","shell.execute_reply.started":"2023-07-31T06:10:18.433321Z","shell.execute_reply":"2023-07-31T06:10:19.697701Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n/opt/conda/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:470: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n  warnings.warn(\nSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['prompt', 'A', 'B', 'C', 'D', 'E', 'answer'],\n    num_rows: 11963\n})"},"metadata":{}}]},{"cell_type":"markdown","source":"And let us now preprocess the examples for training.","metadata":{}},{"cell_type":"code","source":"tokenized_dataset = dataset.map(preprocess, remove_columns=['prompt', 'A', 'B', 'C', 'D', 'E', 'answer'])\ntokenized_dataset","metadata":{"execution":{"iopub.status.busy":"2023-07-31T06:10:19.700702Z","iopub.execute_input":"2023-07-31T06:10:19.701456Z","iopub.status.idle":"2023-07-31T06:10:34.686513Z","shell.execute_reply.started":"2023-07-31T06:10:19.701418Z","shell.execute_reply":"2023-07-31T06:10:34.685441Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/11963 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"66e9da4d05304645bca9f5640a3f9409"}},"metadata":{}},{"name":"stderr","text":"Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['input_ids', 'token_type_ids', 'attention_mask', 'label'],\n    num_rows: 11963\n})"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n\nmodel_id = '/kaggle/input/deberta-v3-large-hf-weights' \nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_use_double_quant=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch.bfloat16\n)\n\ntokenizer = AutoTokenizer.from_pretrained(model_id)","metadata":{"execution":{"iopub.status.busy":"2023-07-31T06:10:34.690604Z","iopub.execute_input":"2023-07-31T06:10:34.690944Z","iopub.status.idle":"2023-07-31T06:10:35.910483Z","shell.execute_reply.started":"2023-07-31T06:10:34.690915Z","shell.execute_reply":"2023-07-31T06:10:35.909463Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\nSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"}]},{"cell_type":"code","source":"model = AutoModelForMultipleChoice.from_pretrained(model_id,quantization_config=bnb_config)","metadata":{"execution":{"iopub.status.busy":"2023-07-31T06:10:35.912303Z","iopub.execute_input":"2023-07-31T06:10:35.912733Z","iopub.status.idle":"2023-07-31T06:10:51.813564Z","shell.execute_reply.started":"2023-07-31T06:10:35.912694Z","shell.execute_reply":"2023-07-31T06:10:51.812597Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"Some weights of DebertaV2ForMultipleChoice were not initialized from the model checkpoint at /kaggle/input/deberta-v3-large-hf-weights and are newly initialized: ['pooler.dense.bias', 'classifier.weight', 'pooler.dense.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from peft import prepare_model_for_kbit_training\n\nmodel.gradient_checkpointing_enable()\nmodel = prepare_model_for_kbit_training(model)","metadata":{"execution":{"iopub.status.busy":"2023-07-31T06:12:08.128108Z","iopub.execute_input":"2023-07-31T06:12:08.128509Z","iopub.status.idle":"2023-07-31T06:12:08.149277Z","shell.execute_reply.started":"2023-07-31T06:12:08.128477Z","shell.execute_reply":"2023-07-31T06:12:08.148318Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def print_trainable_parameters(model):\n    \"\"\"\n    Prints the number of trainable parameters in the model.\n    \"\"\"\n    trainable_params = 0\n    all_param = 0\n    for _, param in model.named_parameters():\n        all_param += param.numel()\n        if param.requires_grad:\n            trainable_params += param.numel()\n    print(\n        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n    )","metadata":{"execution":{"iopub.status.busy":"2023-07-31T06:12:11.148721Z","iopub.execute_input":"2023-07-31T06:12:11.149082Z","iopub.status.idle":"2023-07-31T06:12:11.155973Z","shell.execute_reply.started":"2023-07-31T06:12:11.149047Z","shell.execute_reply":"2023-07-31T06:12:11.155053Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"from peft import LoraConfig, get_peft_model\n\nconfig = LoraConfig(\n    r=8,\n    lora_alpha=32,\n    target_modules=[\"query_key_value\", \"dense\", \"dense_h_to_4h\", \"dense_4h_to_h\"],\n    lora_dropout=0.05,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\"\n)\n\nmodel = get_peft_model(model, config)\nprint_trainable_parameters(model)","metadata":{"execution":{"iopub.status.busy":"2023-07-31T06:12:33.941145Z","iopub.execute_input":"2023-07-31T06:12:33.941568Z","iopub.status.idle":"2023-07-31T06:12:35.916160Z","shell.execute_reply.started":"2023-07-31T06:12:33.941532Z","shell.execute_reply":"2023-07-31T06:12:35.914993Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"trainable params: 2375680 || all params: 285919233 || trainable%: 0.8308919882979681\n","output_type":"stream"}]},{"cell_type":"code","source":"# model = PeftModel.from_pretrained(model, lora_model_dir)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"training_args = TrainingArguments(\n    warmup_ratio=0.8,\n    learning_rate=5e-6,\n    per_device_train_batch_size=1,\n    per_device_eval_batch_size=2,\n    num_train_epochs=1.5,\n    report_to='none',\n    output_dir='.',\n    optim='adamw_torch'\n\n)\n\n# model = AutoModelForMultipleChoice.from_pretrained(deberta_v3_large,quantization_config=bnb_config)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    tokenizer=tokenizer,\n    data_collator=DataCollatorForMultipleChoice(tokenizer=tokenizer),\n    train_dataset=tokenized_dataset,\n)\n\ntrainer.train()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predicting on the test set","metadata":{}},{"cell_type":"markdown","source":"Now that we have trained our model, let us predict on the test set.","metadata":{}},{"cell_type":"code","source":"test_df = pd.read_csv('/kaggle/input/kaggle-llm-science-exam/test.csv')\ntest_df['answer'] = 'A' # dummy answer that allows us to preprocess the test dataset just like we preprocessed the train dataset\n\ntokenized_test_dataset = Dataset.from_pandas(test_df.drop(columns=['id'])).map(preprocess, remove_columns=['prompt', 'A', 'B', 'C', 'D', 'E'])","metadata":{"execution":{"iopub.status.busy":"2023-07-21T03:51:44.400043Z","iopub.execute_input":"2023-07-21T03:51:44.400445Z","iopub.status.idle":"2023-07-21T03:51:44.681849Z","shell.execute_reply.started":"2023-07-21T03:51:44.400416Z","shell.execute_reply":"2023-07-21T03:51:44.680916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_predictions = trainer.predict(tokenized_test_dataset).predictions\ntest_predictions[:4]","metadata":{"execution":{"iopub.status.busy":"2023-07-21T03:51:48.050713Z","iopub.execute_input":"2023-07-21T03:51:48.051096Z","iopub.status.idle":"2023-07-21T03:51:58.358622Z","shell.execute_reply.started":"2023-07-21T03:51:48.051066Z","shell.execute_reply":"2023-07-21T03:51:58.35729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The predictions are values output from the last layer of our neural network.\n\nLet's obtain the predicted answer ids by sorting them from largest to the smallest.","metadata":{}},{"cell_type":"code","source":"predictions_as_ids = np.argsort(-test_predictions, 1)\npredictions_as_ids[:3]","metadata":{"execution":{"iopub.status.busy":"2023-07-21T03:58:13.726252Z","iopub.execute_input":"2023-07-21T03:58:13.726619Z","iopub.status.idle":"2023-07-21T03:58:13.734293Z","shell.execute_reply.started":"2023-07-21T03:58:13.726591Z","shell.execute_reply":"2023-07-21T03:58:13.733158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let us now assign a letter corresponding to each predicted id (0 -> 'A', 1 -> 'B', etc). ","metadata":{}},{"cell_type":"code","source":"predictions_as_answer_letters = np.array(list('ABCDE'))[predictions_as_ids]\npredictions_as_answer_letters[:3]","metadata":{"execution":{"iopub.status.busy":"2023-07-21T03:59:29.450138Z","iopub.execute_input":"2023-07-21T03:59:29.450514Z","iopub.status.idle":"2023-07-21T03:59:29.457655Z","shell.execute_reply.started":"2023-07-21T03:59:29.450482Z","shell.execute_reply":"2023-07-21T03:59:29.456704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions_as_string = test_df['prediction'] = [\n    ' '.join(row) for row in predictions_as_answer_letters[:, :3]\n]\npredictions_as_string[:3]","metadata":{"execution":{"iopub.status.busy":"2023-07-21T04:00:38.222246Z","iopub.execute_input":"2023-07-21T04:00:38.222623Z","iopub.status.idle":"2023-07-21T04:00:38.230438Z","shell.execute_reply.started":"2023-07-21T04:00:38.222595Z","shell.execute_reply":"2023-07-21T04:00:38.229338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = test_df[['id', 'prediction']]\nsubmission.to_csv('submission.csv', index=False)\n\npd.read_csv('submission.csv').head()","metadata":{"execution":{"iopub.status.busy":"2023-07-21T04:01:22.999308Z","iopub.execute_input":"2023-07-21T04:01:22.999674Z","iopub.status.idle":"2023-07-21T04:01:23.015664Z","shell.execute_reply.started":"2023-07-21T04:01:22.999644Z","shell.execute_reply":"2023-07-21T04:01:23.014601Z"},"trusted":true},"execution_count":null,"outputs":[]}]}